<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gait Cycle Analysis Using Single IMU System | Osca Kholopha</title>
    <link rel="stylesheet" href="style.css">
    <style>
        /* Theme Variables */
        :root {
            --content-box-bg: rgba(13, 16, 23, 0.95);
            --content-box-heading: #e0e0e0;
            --content-box-text: #b0b0b0;
        }
        
        body.light-mode {
            --content-box-bg: rgba(240, 242, 245, 0.95);
            --content-box-heading: #1a1a1a;
            --content-box-text: #424242;
        }
        
        .ieee-ref, .figure-mention {
            color: #1a73e8;
            font-weight: bold;
        }
        .ieee-ref-list {
            list-style-type: none;
            padding-left: 0;
        }
        .ieee-ref-list li {
            margin-bottom: 1rem;
            padding-left: 0;
            text-indent: 0;
            line-height: 1.6;
            text-align: left;
        }
        .ieee-ref-list-number {
            display: inline-block;
            min-width: 3rem;
            text-align: left;
            color: #1a73e8;
            font-weight: bold;
            margin-right: 0.5rem;
        }
        .figure-caption {
            font-style: normal !important;
        }
        
        /* Theme Toggle Button - Right Side */
        .theme-toggle {
            background: none;
            border: none;
            cursor: pointer;
            font-size: 20px;
            color: var(--accent);
            transition: transform 0.3s ease;
            padding: 5px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .theme-toggle:hover {
            transform: rotate(20deg) scale(1.1);
        }
        
        /* Hamburger Menu Animation */
        .mobile-menu-btn {
            position: relative;
            width: 30px;
            height: 24px;
            background: none;
            border: none;
            cursor: pointer;
            display: none;
        }
        
        .mobile-menu-btn span {
            position: absolute;
            width: 100%;
            height: 3px;
            background: var(--text-primary);
            border-radius: 3px;
            transition: all 0.3s ease;
            left: 0;
        }
        
        .mobile-menu-btn span:nth-child(1) {
            top: 0;
        }
        
        .mobile-menu-btn span:nth-child(2) {
            top: 50%;
            transform: translateY(-50%);
        }
        
        .mobile-menu-btn span:nth-child(3) {
            bottom: 0;
        }
        
        .mobile-menu-btn.active span:nth-child(1) {
            top: 50%;
            transform: translateY(-50%) rotate(45deg);
        }
        
        .mobile-menu-btn.active span:nth-child(2) {
            opacity: 0;
        }
        
        .mobile-menu-btn.active span:nth-child(3) {
            bottom: 50%;
            transform: translateY(50%) rotate(-45deg);
        }
        
        /* Styled content boxes */
        .content-box {
            background: var(--content-box-bg);
            border-left: 4px solid #1a73e8;
            border-radius: 10px;
            padding: 1.2rem 1.5rem;
            margin: 1.5rem 0;
            transition: background 0.3s ease;
        }
        .content-box h6 {
            color: var(--content-box-heading);
            font-size: 1rem;
            font-weight: 600;
            margin: 0 0 0.8rem 0;
            letter-spacing: 0.5px;
        }
        .content-box ul {
            margin: 0;
            padding-left: 1.2rem;
        }
        .content-box li {
            color: var(--content-box-text);
            margin-bottom: 0.6rem;
            line-height: 1.6;
        }
        .content-box li:last-child {
            margin-bottom: 0;
        }
        .content-box li strong {
            color: var(--content-box-heading);
        }
        .content-box p {
            color: var(--content-box-text);
        }
        
        /* Footer Styles */
        footer {
            background: var(--bg-card);
            border-top: 1px solid var(--border);
            padding: 2rem;
            margin-top: 3rem;
            text-align: center;
            color: var(--text-muted);
        }
        
        footer p {
            margin: 0.5rem 0;
            font-size: 0.9rem;
        }
        
        footer a {
            color: #1a73e8;
            text-decoration: none;
            transition: color 0.3s;
        }
        
        footer a:hover {
            color: var(--accent);
            text-decoration: underline;
        }
        
        /* Theme Toggle Button - Left Side */
        .theme-toggle {
            position: fixed;
            bottom: 2rem;
            left: 2rem;
            background: var(--accent);
            color: var(--bg-primary);
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5rem;
            transition: transform 0.3s;
            z-index: 999;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }
        
        .theme-toggle:hover {
            transform: translateY(-5px);
        }
    </style>
</head>
<body>
    <!-- Animated Grid Background -->
    <div class="grid-background" id="gridBg"></div>

    <!-- Navigation -->
    <nav>
        <div class="nav-container">
            <a href="#" class="nav-brand">Osca Kholopha</a>
            <button class="mobile-menu-btn" id="menuBtn" onclick="toggleMenu()">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-links" id="navLinks">
                <li><a href="#abstract" onclick="closeMenu()">Abstract</a></li>
                <li><a href="#introduction" onclick="closeMenu()">Introduction</a></li>
                <li><a href="#methodology" onclick="closeMenu()">Methodology</a></li>
                <li><a href="#data-processing" onclick="closeMenu()">Data Processing</a></li>
                <li><a href="#results" onclick="closeMenu()">Results</a></li>
                <li><a href="#conclusion" onclick="closeMenu()">Conclusion</a></li>
                <li><a href="#references" onclick="closeMenu()">References</a></li>
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main>
        <!-- Paper Header -->
        <div class="paper-header">
            <h1>PERSON'S GAIT CYCLE ANALYSIS USING SINGLE IMU SYSTEM</h1>
            <div class="paper-meta">
                <strong>Author:</strong> Osca Kholopha <br>
                
                <strong>Course:</strong> MECN4006 - Mechanical Engineering Research Project<br>
                <strong>Project Code:</strong> ATK9<br>
                <strong>Supervisor:</strong> A. Michael<br>
                <strong>Date:</strong> October 5, 2024<br>
                <strong>Witwatersrand University</strong> <br>
            </div>
            <div class="badge">Ethics Clearance: MIAEC 109/24W</div>
        </div>

        <!-- Abstract -->
        <section id="abstract">
            <h2>Abstract</h2>
            <p>This research investigates the use of a single Inertial Measurement Unit (IMU) embedded in an Android device to analyse human gait cycles in real-world conditions. Ethics approval was granted by the Human Research Ethics Committee (Non-Medical) at the University of the Witwatersrand (Clearance No. MIAEC 109/24W).</p>
            <p>A mobile application model was developed to collect IMU data of acceleration, angular velocity, and orientation as well as GPS data for simultaneous motion tracking. GPS readings were used to validate displacement estimates derived from IMU integration, confirming the system's reliability in real-time movement analysis.</p>
            <p>Data was collected across three gait categories: relaxed walking, fast walking, and jogging. Each category was sampled at a distinct rate to match its motion dynamics: 25 Hz for relaxed walking, 75 Hz for fast walking, and 100 Hz for jogging. The device was tested in two placements: inside the pocket and held by hand.</p>
            <p>IMU signals were used to map the stance phases for the lower body and swing phases for the upper body of the gait cycle, forming the basis for gait identification. Jogging produced peak accelerations of 18.2 m/s² and stance durations averaging 0.32 seconds. Relaxed walking showed lower peak accelerations around 9.5 m/s² and longer stance durations near 0.58 seconds. Fast walking exhibited intermediate values, with stride intervals averaging 1.12 seconds. Despite increased signal noise in the handheld configuration, gait phase detection remained reliable.</p>
            <p>These findings demonstrate that a single IMU, combined with adaptive sampling rates and GPS validation, can effectively distinguish gait types and phases. The system offers a low-cost, portable solution for gait analysis with applications in fitness tracking, health monitoring, and biometric identification. Future work will focus on broader demographic testing and machine learning integration.</p>
        </section>

        <!-- Introduction -->
        <section id="introduction">
            <h2>1 INTRODUCTION</h2>
            
            <h3>1.1 Background and Motivation</h3>
            <p>Gait refers to the pattern of movement that enables locomotion. It involves a rhythmic series of leg movements that propel the body forward while conserving energy shown in <span class="figure-mention">Figure 2</span>. The application of gait analysis has grown significantly, finding relevance in areas such as healthcare, sports science, security recognition systems, and fitness. This project focuses on gait analysis for recognition purposes <span class="ieee-ref">[1]</span><span class="ieee-ref">[2]</span>.</p>
            <p>A number of studies have investigated gait analysis, including notable contributions from Chen et al <span class="ieee-ref">[3]</span> and Gaud et al. <span class="ieee-ref">[4]</span>. These researchers employed different data collection methods for gait analyses, characterised into Non-Wearable Sensors (NWS), Wearable Sensors (WS), and Image Processing (IP). NWS and IP systems collect gait data in controlled environments with strategically placed sensors (refer to <span class="figure-mention">Figure 1a</span> and <span class="figure-mention">Figure 1c</span>). In contrast, WS systems offer more flexibility, allowing sensors to be positioned on different parts of the body such as the hips, knees, or feet to measure different aspect of gait (refer to <span class="figure-mention">Figure 1b</span>).</p>
            
            <div class="figure medium">
                <img src="Images/Fig1 Diff sensor type for gait analyses.png" alt="Different types of sensors for gait analyses: a) NWS system, b) WS system, c) IP system">
                <div class="figure-caption">
                    <strong>Figure 1:</strong> Different types of sensors for gait analyses <span class="ieee-ref">[5]</span><span class="ieee-ref">[6]</span><span class="ieee-ref">[7]</span>.<br>
                    a) NWS system &nbsp;&nbsp; b) WS system &nbsp;&nbsp; c) IP system
                </div>
            </div>
            
            <p>NWS and IP systems are primarily designed for controlled environments, and they cannot be suitable for observing gait in daily situations. On the other hand, WS systems can collect data in real-life situation and provide insights into how individuals walk. However, a notable challenge with WS, as shown in <span class="figure-mention">Figure 1b</span>, is that they impact the user's walking pattern and comfort. This issue can be mitigated using small devices with built-in Inertial Measurements Units which will be elaborated upon in the Biomechanics during gait cycle section.</p>
            
            <h3>1.2 Literature Review</h3>
            <p>To examine and analyse walking patterns, understanding gait cycle which is defined as the sequence of movements from one foot strike to the subsequent foot strike on the same side is important for this study <span class="ieee-ref">[8]</span>. This section will explore more on gait cycle, detailing how movements can be analysed and the distinctive gait cycle that can be identified through this analysis. These characteristics can be used for biometric identification to uniquely recognize individuals.</p>
            
            <h4>1.2.1 Person gait cycle</h4>
            <p>A complete gait cycle involves two distinct phases: the stance phase and the swing phase. <span class="figure-mention">Figure 2</span> illustrates the gait cycle of a walking person, highlighting the events occurring in each phase.</p>
            
            <div class="figure medium">
                <img src="Images/Fig2 Gait Cycle.png" alt="Complete gait cycle">
                <div class="figure-caption">
                    <strong>Figure 2:</strong> Complete gait cycle <span class="ieee-ref">[9]</span>
                </div>
            </div>
            
            <h4>1.2.2 Stance and swing phase</h4>
            
            <h5>Stance phase</h5>
            <p>As shown in <span class="figure-mention">Figure 2</span> above, a normal gait cycle begins and ends with the heel strike, which is when the leading foot first contacts the ground. This marks the start of the load response phase, during which the leading foot bears the body's weight as it fully contacts the ground. The heel strike and foot flat events are characterized by a rapid loading of the limb. During the double support phase, both feet are in contact with the ground, providing maximum stability. In the midstance phase, the body moves forward while the opposite leg enters the swing phase. This position is less stable due to the narrow base of support and the higher centre of gravity. The heel off event, where the heel lifts from the ground, signals the transition from midstance to terminal stance. In the terminal stance phase, the body continues to move forward until the pre-swing phase begins, leading to the toe-off event where the toes lose contact with the ground <span class="ieee-ref">[10]</span>.</p>
            
            <h5>Swing phase</h5>
            <p>The swing phase then begins as the swinging leg moves forward past the stance leg, contributing to forward progression. This phase is divided into three sub-phases namely, the initial swing, where the leg accelerates forward; the mid-swing, where the leg passes the opposite stance leg; and the terminal swing, where the leg decelerates in preparation for the next heel strike, which will end the swing phase <span class="ieee-ref">[10]</span>.</p>
            <p>The events in each part of the gait cycle help track the movement of the lower limb. They are important for identifying and distinguishing each step during walking. This swing and stance phases are used to specified different condition when modelling the human walking pattern. Other factor that are induced during the gait cycle are hip rotation and arm swing which are explained below.</p>
            
            <h5>Hip rotation</h5>
            <p>Throughout the gait cycle, hip rotation shows distinct patterns influenced by both static and dynamic positions. During the stance phase, the hip starts in a neutral position at initial contact, then increases internal rotation as weight shifts onto the leg to accommodate ground forces. This internal rotation has a strong correlation with static hip rotation, suggesting that the resting position can help predict movement during walking. In midstance, the connection between static and mid-pivot rotations enhances balance and stability. As the gait transitions to terminal stance, the hip may begin to rotate externally in preparation for push-off. In the swing phase, the hip flexes while continuing to rotate internally to help clear the foot, and then it rotates externally near the end to align properly for the next step <span class="ieee-ref">[11]</span>.</p>
            
            <div class="figure medium">
                <img src="Images/Fig3 Hip rotation.png" alt="Hip rotation during gait cycle">
                <div class="figure-caption">
                    <strong>Figure 3:</strong> Hip rotation during gait cycle <span class="ieee-ref">[26]</span><span class="ieee-ref">[27]</span>.<br>
                    a) Femur rotation &nbsp;&nbsp; b) Rotation during motion
                </div>
            </div>
            
            <h5>Arm swing phases</h5>
            <p>The gait cycle, involving the lower limbs, also results in the movement of the upper body, specifically the arms. During walking, arm swinging can be classified into phases of swing based on their movement and angles relative to the legs. <span class="figure-mention">Figure below</span> shows the definition of swinging of arms.</p>
            
            <div class="figure small">
                <img src="Images/Fig4 Swing movement of arm during Gait Cycle.png" alt="Swing movement of arm during gait cycle">
                <div class="figure-caption">
                    <strong>Figure 4:</strong> Swing movement of arm during gait cycle <span class="ieee-ref">[12]</span>
                </div>
            </div>
            
            <p>Studies have indicated that arm swing plays an important role in maintaining balance and improving energy efficiency during walking. The synchronized movement of the arms counteracts the leg movements as shown in <span class="figure-mention">Figure 5</span>, contributing to stability throughout the gait cycle. As one leg advances, the opposite arm swings forward, providing a counterbalance that helps to prevent falling. This coordination is important for maintaining an upright posture. In terms of energy efficiency, the motion of the arms decreases the energy needed for walking by reducing the angular momentum produced by the legs. This lowered energy expenditure facilitates a more fluid walking pattern, allowing individuals to save energy over longer distances <span class="ieee-ref">[13]</span>.</p>
            
            <div class="figure medium">
                <img src="Images/Fig5 Arm swing movement during gait cycle.png" alt="Arm swing movement during gait cycle">
                <div class="figure-caption">
                    <strong>Figure 5:</strong> Arm swing movement during gait cycle <span class="ieee-ref">[25]</span>
                </div>
            </div>
            
            <p>During the gait cycle shown in <span class="figure-mention">Figure 5</span> above, the positions of the legs and corresponding arm movements are closely coordinated. At P1, when the right heel strikes, the left arm swings forward to maximum. At P2, as the left leg reaches maximum swing, the right arm also moves forward. When the left toe lifts off at P3, the left arm begins to move back. In P4, the right arm transitions forward as the left leg enters mid swing. At P5, during right mid stance, the left arm moves back. This pattern continues: as the left heel strikes at P7, the right arm swings forward, and as the right leg reaches maximum swing at P8, the left arm mirrors this motion.</p>
            
            <h4>1.2.3 Biomechanics during gait cycle</h4>
            <p>Gait analysis is based on two primary methods of system which are kinematics and kinetics <span class="ieee-ref">[10]</span>. Kinetics examines the forces involved in generating walking movements as shown below in <span class="figure-mention">Figure 6a</span>. These forces are calculated from ground-reaction forces and then traced through the lower limbs and joints using biomechanical models. Kinematics (shown in <span class="figure-mention">Figure 6b</span>) focuses on the movement of the body through space, analysing the position and motion of body segments and the angular displacements of joints.</p>
            
            <div class="figure medium">
                <img src="Images/Fig6 Biomechanics analysis for gait cycle.png" alt="Different biomechanics analyses of gait cycle">
                <div class="figure-caption">
                    <strong>Figure 6:</strong> Different biomechanics analyses of gait cycle <span class="ieee-ref">[14]</span>.<br>
                    a) Kinetic gait analysis &nbsp;&nbsp; b) Kinematics gait analysis
                </div>
            </div>
            
            <p>Both types of analyses in <span class="figure-mention">Figure 6</span> can be achieved using wearable sensor systems, which are advantageous due to their affordability and ease of integration to the human body and ability to be used outside laboratory or controlled environment which can be used in everyday real-life activities.</p>
            
            <h5>Kinetic and kinematics sensors</h5>
            <p><span class="figure-mention">Figure 7 below</span> shows different types of sensors and the placement to track the gait parameters.</p>
            
            <div class="figure medium">
                <img src="Images/Fig 7 Sensors for Kinetics and Kinematics motion.png" alt="Sensors for Kinetics and kinematics motion">
                <div class="figure-caption">
                    <strong>Figure 7:</strong> Sensors for Kinetics and kinematics motion <span class="ieee-ref">[22]</span><span class="ieee-ref">[23]</span><span class="ieee-ref">[12]</span>.<br>
                    a) Kinetic sensor &nbsp;&nbsp; b) Kinematics sensor &nbsp;&nbsp; c) Kinematics sensor
                </div>
            </div>
            
            <p>For a comprehensive kinetic gait analysis, sensors are required to measure the ground reaction forces between the foot and the ground. The standard sensors used for this purpose are wearable Ground Reaction Force (GRF) sensors as shown in <span class="figure-mention">Figure 7a</span>. In contrast, kinematic gait analysis as shown in <span class="figure-mention">Figure 7b</span> and <span class="figure-mention">Figure 7c</span> makes use of Inertial Measurement Units (IMUs). IMUs are preferred as they can be mounted on various body parts relevant to the study, such as the feet, hips, or femur, thereby offering a broad range of gait analysis. IMUs are commonly incorporated into wearable devices, including smartwatches and smartphones, which can be used during everyday activities without affecting the individual's walking pattern.</p>
            <p>The use of GRF sensors will compromise the accuracy of gait analysis due to potential alterations in the user's walking pattern and comfort. GRF sensors are often integrated into shoes or insoles, which can interfere with the user's preferred footwear and overall comfort. Given these considerations, kinematic gait analysis using IMU is more suitable for this research project due to their minimal impact on the user's natural walking pattern and their flexibility in placement.</p>
            
            <h5>IMU Sensors for Gait Cycle</h5>
            <p>An Inertial Measurement Unit (IMU) is a device that combines several sensors to track different types of motion and orientation. It has accelerometers that measure acceleration along three axes, detecting changes in speed and direction. The IMU also includes gyroscopes that measure the rate of rotation around three axes, showing how the device or system is rotating. It also allows the measuring of the orientation of the device <span class="ieee-ref">[15]</span>.</p>
            
            <h5>Accelerometer sensor in gait cycle</h5>
            <p>In gait analysis, an accelerometer sensor is used to measure the directional acceleration of motion. The acceleration recorded by the accelerometer corresponds to the body part on which the sensor is mounted. <span class="figure-mention">Figure 8a</span> illustrates the accelerometer and the directions in which acceleration is measured. <span class="figure-mention">Figure 8b</span> shows the movement of the person and the different axes involved (x, y, and z). The acceleration along these axes is denoted as ẍ, ÿ and z̈ respectively.</p>
            
            <div class="figure medium">
                <img src="Images/Fig8 Acceleration Sensor and the direction of human motion.png" alt="Acceleration sensor and the direction of human motion">
                <div class="figure-caption">
                    <strong>Figure 8:</strong> Acceleration sensor and the direction of human motion <span class="ieee-ref">[16]</span><span class="ieee-ref">[17]</span>.<br>
                    a) Accelerometer &nbsp;&nbsp; b) Directional motion of human
                </div>
            </div>
            
            <h5>Gyroscope sensor in gait cycle</h5>
            <p>Because some segments of the body where the IMU is mounted for gait analyses does not only translate but also rotates during movement, it is important to measure the angular velocity of specific body parts as they rotate around particular axes and the angle of rotation. As shown in the <span class="figure-mention">Figure 9 below</span>, walking involves not only forward motion but also the rotational dynamics of the lower limb segments (thigh and shank) at their joints. This combination of translational and rotational movement contributes to the overall gait cycle, which is characterized by angular velocity.</p>
            
            <div class="figure medium">
                <img src="Images/Fig9 Gyroscope angular velocity sensor and dirrectional human motion.png" alt="Gyroscope angular velocity directional measurements relative to the human walking">
                <div class="figure-caption">
                    <strong>Figure 9:</strong> Gyroscope angular velocity directional measurements relative to the human walking.<span class="ieee-ref">[16]</span><br>
                    a) Gyroscope &nbsp;&nbsp; b) Directional human motion
                </div>
            </div>
            
            <p>The gyroscope measurements (shown in <span class="figure-mention">Figure 9a</span>) will capture the angular velocity of the lower limb segment where the IMU sensor is mounted. These measurements are oriented within the three-dimensional Cartesian plane of the individual, as illustrated in <span class="figure-mention">Figure 9b</span>. The angular velocity is expressed in radians per second (rad/s) and is categorized into three rotational axes θ̇x, θ̇y, and θ̇z representing the angular velocity about the x, y, and z directions, respectively. These measurements are important for analysing the gait cycle and understanding limb dynamics during movement.</p>
            
            <h4>1.2.4 Related Work</h4>
            <p>Recent studies have increasingly focused on analysing the gait cycle of individuals using wearable sensor systems that make use of Inertial Measurement Units (IMUs). The use of IMUs lies in their cost-effectiveness and versatility compared to traditional laboratory setups, which often constrain movement and create controlled environments that may not accurately reflect real-world conditions. This limitation makes them less applicable for monitoring human gait in real-world scenarios <span class="ieee-ref">[18]</span>.</p>
            <p>Most previous research has utilized either two or three IMU sensors placed on the lower limb. In studies employing two IMU sensors, they are typically positioned on the hip and shank. For example, the study by Mitchelle et al. for IMU Sensor to Segment Calibration <span class="ieee-ref">[19]</span> illustrates this setup. Conversely, studies that implement three IMU sensors add an extra sensor on the foot, as shown in the work of Tobias et al. on IMU to Segment and Orientation Alignment for Lower Body Using DL <span class="ieee-ref">[20]</span>. <span class="figure-mention">Figure 10a</span> and <span class="figure-mention">Figure 10b</span> provide visual representations of how the double and single IMU sensors are arranged on the lower limb segments for analysing the gait cycle.</p>
            
            <div class="figure medium">
                <img src="Images/Fig10.png" alt="The 2 and 3 IMU sensor system configuration for gait cycle">
                <div class="figure-caption">
                    <strong>Figure 10:</strong> The 2 and 3 IMU sensor system configuration for gait cycle <span class="ieee-ref">[19]</span><span class="ieee-ref">[20]</span>.<br>
                    a) Two IMU system &nbsp;&nbsp; b) Three IMU system
                </div>
            </div>
            
            <h4>1.2.5 Research objectives</h4>
            
            <div class="content-box">
                <h6>The aims of this research are as follows:</h6>
                <ul>
                    <li><strong>Application Development:</strong> Develop an Android application model that retrieves Inertial Measurement Unit (IMU) values of acceleration, angular velocity, and orientation during motion</li>
                    <li><strong>Gait Cycle Analysis:</strong> Analyse the gait cycle using the retrieved IMU data during movement</li>
                </ul>
            </div>
        </section>

        <!-- Methodology -->
        <section id="methodology">
            <h2>2 METHODOLOGY</h2>
            <p>Approval for this research project was granted by the Human Research Ethics Committee (Non-Medical) due to the collection of data from a user. The ethics clearance number for this project is MIAEC 109/24W. One participant, a male in his 20s, contributed valuable insights for the research. The flow diagram below illustrates the methodology of this research, detailing the process from data collection to data processing. Further details are provided in the following sections.</p>
            
            <div class="figure large">
                <img src="Images/Fig11 Flow diagram of the data collection to results.png" alt="Flow diagram of the data collection to results">
                <div class="figure-caption">
                    <strong>Figure 11:</strong> Flow diagram of the data collection to results
                </div>
            </div>
            
            <h3>2.1 Development of Model for Data Collection</h3>
            <p>To access the IMU and GPS hardware values of the phone, an application model capable of retrieving real-time data from the sensors was developed. The application was created using the Android Studio Integrated Development Environment (IDE) version Ladybug | 2024.2.1 due to its features including an emulator for virtual testing during development without needing a physical device, and a layout editor for designing a user interface with built-in controls. The programming language used was Kotlin, as it allows for importing resources and libraries from Google services such as location that improve application performance for tracking.</p>
            
            <p>The developed application model for data retrieving includes a user interface that displays sensor readings from the GPS and IMU hardware. The <span class="figure-mention">Figure 13</span> illustrates the layout of each section. The kinematics under IMU include acceleration, which records linear acceleration in the x, y, and z directions; angular velocity around the x, y, and z axes of the phone; and orientation, which captures the tilting of the phone based on pitch, roll, and yaw, as shown in <span class="figure-mention">Figure 12</span>. Both types of kinematic data are updated using the predefined update rates of SENSOR_DELAY_FASTEST and SENSOR_DELAY_GAME, which provide the quickest updates reflecting the current state of motion.</p>
            
            <div class="figure small">
                <img src="Images/Fig12 Mobile phone coordinate system.png" alt="Mobile phone coordinate system">
                <div class="figure-caption">
                    <strong>Figure 12:</strong> Mobile phone coordinate system <span class="ieee-ref">[28]</span>
                </div>
            </div>
            
            <p>For location tracking, GPS functionality was integrated into the user interface, enabling visualization of longitude and latitude for tracking the path taken, as well as calculating distance and average speed. For GPS to function, permission to access the device's location must be granted.</p>
            <p>The user controls are designed to allow users to start and stop motion sensing on the device, with the ability to log motion data to a database at a specified sample rate, starting as low as 1 Hz. The database used is Firebase Realtime Database, which supports the storage of real-time data. Firebase was chosen for its provision of 1 GB of total storage and 10 GB/month of download capacity.</p>
            
            <p>The <span class="figure-mention">Figure 13 below</span> illustrates the developed model for data collection designed to work on Android phones. The directions of acceleration, angular velocity, and orientation are based in the mobile phone coordinate presented in <span class="figure-mention">Figure 12 above</span>.</p>
            
            <div class="figure medium">
                <img src="Images/Fig13 User  Interface for data retriving and collection model.png" alt="User Interface (UI) for data retrieving and collection model">
                <div class="figure-caption">
                    <strong>Figure 13:</strong> User Interface (UI) for data retrieving and collection model
                </div>
            </div>
            
            <p>To ensure the developed model code is functioning correctly, the virtual emulator and virtual sensors of the phone were configured for code validation. This process involved adjusting the sensor values to simulate various conditions and then monitoring the model's user interface in the emulator. This approach was to verify that the displayed values for acceleration, angular velocity, and orientation matched the expected outputs. Each adjustment was carefully tested to confirm that the code processes the sensor data accurately. The <span class="figure-mention">Figure 14 below</span> shows the process of code functionality configuration.</p>
            
            <div class="figure medium">
                <img src="Images/Fig14 Verfying the functionality of the code.png" alt="Verifying the functionality of the code">
                <div class="figure-caption">
                    <strong>Figure 14:</strong> Verifying the functionality of the code.<br>
                    a) Acceleration testing &nbsp;&nbsp; b) Orientation testing &nbsp;&nbsp; c) Angular acceleration testing &nbsp;&nbsp; d) GPS visualisation
                </div>
            </div>
            
            <h3>2.2 Data Collection Approach</h3>
            <p>The experiment was conducted using a Huawei smartphone with the app installed. Motion data was recorded with the phone mounted on two different segments of the body: the shank, thigh, hand, and upper arm. For each body segment, motion recordings were taken three times, differentiated by the type of movement: relaxed walking, fast walking, and jogging.</p>
            <p>The motion data recorded from the Inertial Measurement Unit (IMU) included acceleration, orientation, and pitch, while GPS data provided longitude and latitude for motion tracking. For relaxed walking, a sampling rate of 25 Hz was set; for fast walking, the sampling rate increased to 50 Hz; and for jogging, a sampling rate of 75 Hz was employed. This increase in sampling rate from relaxed walking to jogging was implemented to accommodate the faster changes in motion occurring during these activities. As the speed of movement increases, the kinematic changes also require a higher sampling rate to accurately capture these variations, ensuring that the collected motion data reflects the true nature of the movements.</p>
            <p>The same device was used throughout the data collection process, with a minimum distance travelled of 20 meters. This distance was chosen to ensure that the requested sampling rate did not exceed the limits of the database. Data collection was performed outside the building, as GPS tracking yields more accurate results outdoors compared to indoor settings.</p>
        </section>

        <!-- Data Processing -->
        <section id="data-processing">
            <h2>3 DATA PROCESSING</h2>
            <p>This section presents the pre-processing of the data retrieved during the motion captured in the experiments.</p>
            
            <h3>3.1 Raw Data Cleaning and Preprocessing</h3>
            <p>The current raw data from the Inertial Measurement Unit (IMU) is displayed below in <span class="figure-mention">Figure 15</span> in graphical format due to the large volume of sampled values. This dataset presents only a relaxed walking scenario, with the phone placed in the left side pocket.</p>
            
            <div class="figure medium">
                <img src="Images/Fig15 .png" alt="IMU graphical raw data for a relaxed walking with a phone on the left side pocket">
                <div class="figure-caption">
                    <strong>Figure 15:</strong> IMU graphical raw data for a relaxed walking with a phone on the left side pocket
                </div>
            </div>
            
            <p>The results in <span class="figure-mention">Figure 15</span> represent the acceleration in the x, y, and z directions, as well as the angular velocities about the x, y, and z axes. Additionally, the orientation data is included, indicating pitch, roll, and yaw angles.</p>
            <p>The raw data from the GPS is presented in <span class="figure-mention">Figure 16 below</span>, corresponding to the relaxed walking scenario with the phone in the left side pocket. This dataset includes latitude, longitude, total distance, and average speed.</p>
            
            <p>The distance between the two locations defined by longitude and latitude was determined using the Haversine formula, a mathematical approach for measuring the distance between two points <span class="ieee-ref">[21]</span>. The formula calculates the distance along the shortest path between the points, which are specified by their latitude and longitude coordinates.</p>
            
            <div class="figure small">
                <div class="equation-img">
                    <img src="Images/EQ1 Distance Equation.png" alt="Haversine Distance Equation">
                </div>
                <div class="figure-caption">
                    <strong>Equation 1:</strong> Haversine formula for calculating distance between two GPS coordinates.
                </div>
            </div>
            
            <p>where R is the Earth's radius (6,371 km), φ₁−φ₂ are the latitudes of the two locations (in radians), and λ₁−λ₂ are the longitudes of the two locations (in radians).</p>
            
            <div class="figure medium">
                <img src="Images/Fig16 Processing of GPS data to get the distance and average speed.png" alt="Processing of GPS data to get the distance and average speed">
                <div class="figure-caption">
                    <strong>Figure 16:</strong> Processing of GPS data to get the distance and average speed
                </div>
            </div>
            
            <p>During pre-processing, the first 75 and last 75 sampled values are removed for the relaxed walking scenario. These values represent the initial and final 3 seconds of data collection, which do not accurately capture true motion, as they include the moments of placing the phone in the pocket and removing it.</p>
            <p>For the fast-walking scenario, the first and last 150 samples are discarded, reflecting the average sampling rate used during this activity. In the case of jogging, the first and last 225 samples are removed, as this data is collected at a higher sampling rate. This method ensures that the processed data accurately reflects the actual motion for each activity.</p>
            
            <h3>3.2 Verification and Validation of the data</h3>
            <p>To validate the IMU, the GPS was used. Before using the GPS for validation, the recorded latitude and longitude obtained from the model, which defined the tracking of the person, were traced on Google Maps. This was done to determine whether the coordinates accurately represented the actual path travelled during data collection. The latitude and longitude data from the model for each experiment are shown in the figure below for path tracking.</p>
            
            <div class="figure medium">
                <img src="Images/Fig17 Traced path during the data collection.png" alt="Traced path during the data collection">
                <div class="figure-caption">
                    <strong>Figure 17:</strong> Traced path during the data collection
                </div>
            </div>
            
            <p>In both cases, the latitude accurately represented the actual path taken during the motion. The coordinates could be used to validate the sensor, as they effectively traced the actual walking path, as illustrated in the <span class="figure-mention">Figure 17 above</span>.</p>
            <p>To analyse the data collected from the Inertial Measurement Unit (IMU), which includes acceleration ẍ(t) measurements in three-dimensional space, integration techniques from calculus is used. The recorded acceleration can be integrated to determine the velocity ẋ(t) and position displacement x(t) over time, using the following equations.</p>
            
            <p><strong>Velocity calculation:</strong></p>
            <div class="figure small">
                <div class="equation-img">
                    <img src="Images/EQ2 Velocity Equation.png" alt="Velocity Equation">
                </div>
                <div class="figure-caption">
                    <strong>Equation 2:</strong> Velocity calculation from acceleration data.
                </div>
            </div>
            <p>where ẋ₀ is the initial velocity at time t₀</p>
            
            <p><strong>Position calculation:</strong></p>
            <div class="figure small">
                <div class="equation-img">
                    <img src="Images/EQ3 Position Equation.png" alt="Position Equation">
                </div>
                <div class="figure-caption">
                    <strong>Equation 3:</strong> Position calculation from velocity data.
                </div>
            </div>
            <p>where x₀ is the initial position at time t₀</p>
            
            <p>Because the acceleration data collected from the IMU is not continuous and consists of discrete samples taken at various points during motion, numerical integration methods is employed to accurately estimate velocity and position. The cumulative trapezoidal rule is used for numerical integration to handle the discrete nature of the data. The numerical integration equations used are detailed below.</p>
            
            <p><strong>Numerical Integration</strong></p>
            <p><strong>Velocity approximation:</strong></p>
            <div class="figure small">
                <div class="equation-img">
                    <img src="Images/EQ4 Velocity Approxiamtion.png" alt="Velocity Approximation using Trapezoidal Rule">
                </div>
                <div class="figure-caption">
                    <strong>Equation 4:</strong> Velocity approximation using the cumulative trapezoidal rule.
                </div>
            </div>
            <p>where ẋ(tᵢ) is the estimated velocity at time tᵢ</p>
            
            <p><strong>Position approximation:</strong></p>
            <div class="figure small">
                <div class="equation-img">
                    <img src="Images/EQ5 Position Approximation.png" alt="Position Approximation using Trapezoidal Rule">
                </div>
                <div class="figure-caption">
                    <strong>Equation 5:</strong> Position approximation using the cumulative trapezoidal rule.
                </div>
            </div>
            <p>where x(tᵢ) is the estimated position at time tᵢ</p>
            
            <p>By applying these numerical integration techniques, both velocity and position can be effectively estimated based on the discrete acceleration data collected from the IMU.</p>
            
            <div class="figure medium">
                <img src="Images/Fig18 Using IMU to approximate the Distance.png" alt="Using IMU to approximate the distance">
                <div class="figure-caption">
                    <strong>Figure 18:</strong> Using IMU to approximate the distance
                </div>
            </div>
            
            <div class="figure medium">
                <img src="Images/Fi19 IMU and GPS total distance validation.png" alt="IMU and GPS total distance validation">
                <div class="figure-caption">
                    <strong>Figure 19:</strong> IMU and GPS total distance validation.<br>
                    a) GPS Total distance &nbsp;&nbsp; b) IMU Total distance
                </div>
            </div>
            
            <p>The comparison between GPS and IMU total distance <span class="figure-mention">Figure 19</span> shows that although the GPS output increases linearly while the IMU follows a nonlinear trend, both methods yield comparable total distances over the same time duration.</p>
        </section>

        <!-- Results -->
        <section id="results">
            <h2>4 RESULTS AND DISCUSSION</h2>
            
            <h3>4.1 Gait Identification from IMU</h3>
            <p>This section presents an analysis of the gait cycle phases derived from data collected during motion. The focus is on the mapping of the Stance and Swing phases, as described in the literature review. The analysis includes three types of gaits: relaxed walking, fast walking, and jogging.</p>
            
            <h4>4.1.1 Relaxed walking gait cycle</h4>
            <p>For the motion of the user when relaxed walking with the phone inside the left pocket, after being processed were mapped with the gait cycle as shown below in <span class="figure-mention">Figure 20</span>.</p>
            
            <div class="figure large">
                <img src="Images/Fig20 Mapping of relaxed walking motion to gate cycle.png" alt="Mapping of relaxed walking motion to gait cycle">
                <div class="figure-caption">
                    <strong>Figure 20:</strong> Mapping of relaxed walking motion to gait cycle
                </div>
            </div>
            
            <p>In the case of relaxed walking, where the user carried a phone in the left pocket, the processed data was used to map the gait cycle, as depicted in <span class="figure-mention">Figure 20</span>.</p>
            
            <div class="content-box">
                <h6>Stance Phase Dynamics:</h6>
                <p style="color: #b0b0b0; margin-bottom: 0.8rem;">From the analysis, gait identification was primarily based on three key parameters: acceleration in the x-direction, angular velocity around the y-axis, and the tilt angle of yaw.</p>
                <ul>
                    <li><strong>Mid-stance:</strong> Leg straight forward, perpendicular to ground, yaw angle at zero</li>
                    <li><strong>Terminal stance transition:</strong> Leg angle reaches minimum (~-15°) as leg extends backward</li>
                    <li><strong>Terminal stance:</strong> Leg at furthest backward position with minimal acceleration</li>
                </ul>
            </div>
            
            <div class="content-box">
                <h6>Pre-Swing Phase Dynamics:</h6>
                <ul>
                    <li><strong>Pre-swing:</strong> Leg accelerates forward from terminal stance</li>
                    <li><strong>Toe-off and mid-swing:</strong> Increasing thigh angle as leg moves forward</li>
                    <li><strong>Peak position:</strong> Peak thigh angle at mid-swing with leg fully extended forward</li>
                </ul>
            </div>
            
            <div class="content-box">
                <h6>Swing Phase Dynamics:</h6>
                <ul>
                    <li><strong>Terminal swing:</strong> Sudden deceleration in preparation for heel strike</li>
                    <li><strong>Loading response:</strong> Angle decreases, acceleration approaches zero as leg absorbs impact</li>
                    <li><strong>Return to mid-stance:</strong> Completing the gait cycle</li>
                </ul>
            </div>
            
            <p>The analysis aligns well with the established understanding of the gait cycle, as outlined in the literature review. A normal gait cycle begins and ends with a heel strike, marking the transition from the load response phase to double support, where both feet contact the ground. The mid-stance phase, characterized by the opposite leg entering the swing phase, is essential for forward progression.</p>
            
            <h4>4.1.2 Fast walking gait cycle</h4>
            <p>During fast walking, the retrieved data mapped with the gait cycle is illustrated in <span class="figure-mention">Figure 21</span>. The analysis of fast walking relies on three key parameters: acceleration in the x-direction, angular velocity about the z-axis, and orientation indicated by the yaw angle.</p>
            
            <div class="figure large">
                <img src="Images/Fig21 Mapping gait cycle for fast walking with phone inside left pocket.png" alt="Mapping gait cycle for fast walking with phone inside left pocket">
                <div class="figure-caption">
                    <strong>Figure 21:</strong> Mapping gait cycle for fast walking with phone inside left pocket
                </div>
            </div>
            
            <p>For this analysis, S1 is designated as the reference point. S2 represents the maximum angle, approximately -5°, which corresponds to the terminal swing phase of the gait cycle. This maximum angle is critical as it indicates the transition into the next phase.</p>
            
            <div class="content-box">
                <h6>Fast Walking Gait Dynamics:</h6>
                <ul>
                    <li><strong>Heel Strike and Loading Response:</strong> At S2, heel strike occurs with acceleration of ~5 m/s². Phone shifts in pocket due to impact inertia.</li>
                    <li><strong>Loading Response (S2 → S3):</strong> Leg absorbs ground strike impact, maintaining stability for next phase.</li>
                    <li><strong>Terminal Stance (S3):</strong> Angle at lowest (~-17°), maximum stability with body weight on stance leg.</li>
                    <li><strong>Forward Swing:</strong> Leg transitions to swing phase, acceleration peaks at ~12 m/s² during forward propulsion.</li>
                </ul>
            </div>
            
            <h3>4.2 Arm Swing Cycle Identification from IMU</h3>
            <p>This section presents the mapping of the arm motion as it correlates to the phases of the gait cycle, as detailed in the literature review, with the corresponding figure illustrating the different swing phases of the arm. The phases are for relaxed walking, fast walking, and jogging with a mobile held by left hand.</p>
            
            <h4>4.2.1 Relaxed walking arm swing cycle</h4>
            <p>The motion of relaxed walking with the phone held in the left hand is shown in the figure below, where the movement is divided into distinct segments. The stick figure, though not drawn to scale, represents the arm swing motion at various points in the gait cycle. These segments highlight the coordination between the arm's forward and backward swings, which correspond to the leg movements, as detailed in the gait cycle analysis. The figure illustrates how the arm's motion varies throughout the cycle, contributing to overall balance and energy efficiency during walking. Each segment captures a specific phase of the arm swing.</p>
            
            <div class="figure large">
                <img src="Images/Fig22 Mapping of arm swing cycle to the retrvied data from IMU.png" alt="Mapping of arm swing cycle to the retrieved data from IMU">
                <div class="figure-caption">
                    <strong>Figure 22:</strong> Mapping of arm swing cycle to the retrieved data from IMU
                </div>
            </div>
            
            <p><strong>Mapping of the Arm Swing</strong></p>
            <p>The cycle of the arm swing is mapped starting from the mid-swing forward direction (denoted by position S1). In this position:</p>
            
            <div class="content-box">
                <h6>Arm Swing Cycle Mapping:</h6>
                <ul>
                    <li><strong>S1 (Mid-Swing Forward):</strong> Yaw angle at 0°, arm parallel to body, minimum acceleration</li>
                    <li><strong>S1 to S2 (Forward Swing):</strong> Arm accelerates forward to max 5 m/s², angle increases to ~38°, angular velocity reaches 0 rad/s at S2</li>
                    <li><strong>S2 to S3 (Backward Swing):</strong> Direction reverses, arm swings backward to mid-swing position, orientation returns to 0°</li>
                </ul>
            </div>
            
            <h4>4.2.2 Fast walking arm swing cycle</h4>
            <p>The mapping results for fast walking with the phone held in the left hand are shown in the figure below. This mapping illustrates the differences in the arm swing dynamics compared to relaxed walking, including variations in acceleration, swing angles, and angular velocity.</p>
            
            <div class="figure large">
                <img src="Images/Fig23 Mapping of Fast walking arm swing cycle.png" alt="Mapping of fast walking arm swing cycle">
                <div class="figure-caption">
                    <strong>Figure 23:</strong> Mapping of fast walking arm swing cycle
                </div>
            </div>
            
            <p>During fast walking, the arm swing pattern follows a similar cycle to relaxed walking, but with notable differences in terms of cycle time, acceleration, and swing angles. While the basic coordination of arm and leg movements remains the same, the parameters differ due to the increased speed of walking.</p>
            
            <div class="content-box">
                <h6>Fast Walking Arm Swing Comparison:</h6>
                <ul>
                    <li><strong>Maximum acceleration:</strong> 10 m/s² (min: -10 m/s²) — significantly higher than relaxed walking</li>
                    <li><strong>Swing angles:</strong> Range of 58° to -20° — increased range of motion</li>
                    <li><strong>Angular velocity:</strong> 5 rad/s (min: -5 rad/s) — faster transitions between swings</li>
                </ul>
            </div>
            
            <p>These differences reflect the increased intensity and speed of the movement in fast walking, which leads to higher accelerations, greater angular velocities, and a broader range of arm motion compared to the relaxed walking cycle.</p>
            
            <h3>4.3 Overall Identified Gait Cycle Statistics</h3>
            <p>The overall calculated gaits for relaxed, fast, and jogging motions, with the mobile phone placed in both the pocket and the hand, are presented in Table 1 and Table 2.</p>
            
            <div class="table-container">
                <table>
                    <caption><strong>Table 1:</strong> Calculated gaits for pocket placement of the mobile phone</caption>
                    <thead>
                        <tr>
                            <th></th>
                            <th>Mean</th>
                            <th>Max</th>
                            <th>Min</th>
                            <th>Std</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td colspan="5"><strong>Acceleration (m/s²)</strong></td></tr>
                        <tr><td>Relaxed</td><td>-0.31695</td><td>7.93916</td><td>-20.2818</td><td>2.70778</td></tr>
                        <tr><td>Fast</td><td>-0.09044</td><td>8.86816</td><td>-19.0051</td><td>3.14046</td></tr>
                        <tr><td>Jogging</td><td>0.37244</td><td>10.2242</td><td>-26.9618</td><td>5.12404</td></tr>
                        <tr><td colspan="5"><strong>Angular Velocity (rad/s)</strong></td></tr>
                        <tr><td>Relaxed</td><td>0.03823</td><td>2.79464</td><td>-2.18652</td><td>0.85096</td></tr>
                        <tr><td>Fast</td><td>0.01285</td><td>6.64679</td><td>-3.52965</td><td>1.43217</td></tr>
                        <tr><td>Jogging</td><td>0.07408</td><td>6.63614</td><td>-5.70925</td><td>1.9805</td></tr>
                        <tr><td colspan="5"><strong>Orientation [Yaw] (degree)</strong></td></tr>
                        <tr><td>Relaxed</td><td>-3.91995</td><td>6.9226</td><td>-17.6953</td><td>6.37232</td></tr>
                        <tr><td>Fast</td><td>-3.2336</td><td>66.0971</td><td>-13.9558</td><td>9.24381</td></tr>
                        <tr><td>Jogging</td><td>-9.33518</td><td>-0.67476</td><td>-20.3876</td><td>3.81914</td></tr>
                    </tbody>
                </table>
            </div>
            
            <div class="table-container">
                <table>
                    <caption><strong>Table 2:</strong> Calculated gaits for hand placement of the mobile phone</caption>
                    <thead>
                        <tr>
                            <th></th>
                            <th>Mean</th>
                            <th>Max</th>
                            <th>Min</th>
                            <th>Std</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td colspan="5"><strong>Acceleration (m/s²)</strong></td></tr>
                        <tr><td>Relaxed</td><td>0.067</td><td>7.0317</td><td>-6.448</td><td>3.8087</td></tr>
                        <tr><td>Fast</td><td>-0.034</td><td>13.211</td><td>-12.66</td><td>6.4649</td></tr>
                        <tr><td>Jogging</td><td>3.3617</td><td>35.945</td><td>-28.08</td><td>14.6</td></tr>
                        <tr><td colspan="5"><strong>Angular Velocity (rad/s)</strong></td></tr>
                        <tr><td>Relaxed</td><td>-0.016</td><td>2.7106</td><td>-1.534</td><td>0.6168</td></tr>
                        <tr><td>Fast</td><td>-0.005</td><td>2.6347</td><td>-3.63</td><td>0.766</td></tr>
                        <tr><td>Jogging</td><td>-0.076</td><td>4.417</td><td>-5.721</td><td>1.7179</td></tr>
                        <tr><td colspan="5"><strong>Orientation [Yaw] (degree)</strong></td></tr>
                        <tr><td>Relaxed</td><td>13.683</td><td>45.25</td><td>-15.8</td><td>16.805</td></tr>
                        <tr><td>Fast</td><td>13.039</td><td>74.987</td><td>-34.28</td><td>29.038</td></tr>
                        <tr><td>Jogging</td><td>44.586</td><td>80.673</td><td>-12.3</td><td>23.256</td></tr>
                    </tbody>
                </table>
            </div>
            
            <h4>4.3.1 Rate of the forward movement</h4>
            <p>Acceleration along the x-axis provides an important measure of the forward motion of the body during walking. The results from the different motion conditions—relaxed, fast, and jogging—showed clear distinctions in both the magnitude and variability of acceleration.</p>
            
            <h5>Phone inside left side pocket for relaxed, fast, and jogging</h5>
            
            <div class="content-box">
                <h6>Acceleration Patterns by Movement Type:</h6>
                <ul>
                    <li><strong>Relaxed walking:</strong> Mean -0.3169 m/s² with std dev 2.7078 m/s², max 7.9392 m/s², min -20.2818 m/s² — path discontinuities caused high acceleration values</li>
                    <li><strong>Fast walking:</strong> Mean -0.0904 m/s² with std dev 3.1405 m/s² — greater fluctuations in acceleration due to pace changes</li>
                    <li><strong>Jogging:</strong> Mean 0.3724 m/s² with std dev 5.1240 m/s², max 10.2242 m/s² — positive forward motion with higher forces and irregular patterns</li>
                </ul>
            </div>
            
            <h5>Phone held by left Hand</h5>
            
            <div class="content-box">
                <h6>Hand-Held Acceleration Comparison:</h6>
                <ul>
                    <li><strong>Relaxed walking:</strong> Mean 0.0670 m/s² with std dev 3.8087 — more stable movement, larger variability in hand-held condition</li>
                    <li><strong>Fast walking:</strong> Std dev increased to 6.4649, max acceleration 13.2112 m/s² — more dynamic movement compared to pocket</li>
                    <li><strong>Jogging:</strong> Mean 3.3617 m/s² with std dev 14.5998, max 35.9450 m/s² — highly variable with intense motion, highest acceleration values</li>
                </ul>
            </div>
            
            <h4>4.3.2 Orientation of body segment</h4>
            <p>Yaw in this research project was describing the angular displacement of the device relative to the x-axis, indicating the angle of the thigh during different phases of walking. A minimum yaw corresponds to the terminal stance phase, where the leg is fully extended whereas maximum yaw indicates the terminal swing phase, just before the heel strike, where the leg is in the swing phase.</p>
            
            <h5>Phone inside a pocket</h5>
            
            <div class="content-box">
                <h6>Yaw Orientation Analysis (Pocket):</h6>
                <ul>
                    <li><strong>Relaxed motion:</strong> Mean yaw -3.92° with std dev 6.37° — thigh positioned closer to terminal stance phase with some variability</li>
                    <li><strong>Fast walk:</strong> Mean yaw -3.23° with std dev 3.82° — more stable thigh rotation, less variability</li>
                    <li><strong>Jogging:</strong> Mean yaw -3.23° with std dev 9.24° — significant rotational movement due to increased dynamics</li>
                </ul>
            </div>
            
            <h5>Phone held by left hand</h5>
            
            <div class="content-box">
                <h6>Yaw Orientation Analysis (Hand-Held):</h6>
                <ul>
                    <li><strong>Relaxed walking:</strong> Mean yaw 13.68° with std dev 16.81° — shift toward terminal swing phase, substantial variation due to body rotation</li>
                    <li><strong>Fast walk:</strong> Mean yaw 13.04° with std dev 29.04° — thigh rotation in terminal swing phase, high variability from faster movements</li>
                    <li><strong>Jogging:</strong> Mean yaw 44.59° with std dev 23.26° — highest variation, significant rotation between terminal swing and heel strike phases</li>
                </ul>
            </div>
        </section>

        <!-- Conclusion -->
        <section id="conclusion">
            <h2>5 CONCLUSIONS AND RECOMMENDATIONS</h2>
            <p>This study demonstrates the feasibility and effectiveness of using a single Inertial Measurement Unit (IMU) for gait cycle analysis in real-world settings, facilitated by a custom Android application. The project successfully identified distinct gait phases (stance and swing) across various movement types, including relaxed walking, fast walking, and jogging. Results show that a single IMU system, positioned at various points on the body, can capture essential gait characteristics such as acceleration, angular velocity, and orientation, achieving an analysis quality comparable to multi-sensor setups. This portable approach presents a practical and non-intrusive solution for gait analysis, with potential applications in healthcare for patient mobility monitoring, in security for biometric identification, and in fitness for tracking personal performance.</p>
            
            <h3>Recommendations</h3>
            <p>To build on these findings, future work should consider expanding data collection by incorporating a more diverse participant group, including individuals of varying age groups, body types, and gait abnormalities, to improve model robustness and generalizability. Enhancing the Android application's interface and adding automated data cleaning features would improve usability and broaden accessibility. Implementing real-time gait analysis and feedback functionalities could provide immediate insights, which would be especially valuable in rehabilitation and fitness tracking contexts.</p>
        </section>

        <!-- References -->
        <section id="references">
            <h2>REFERENCES</h2>
            <ul class="ieee-ref-list">
                <li><span class="ieee-ref-list-number">[1]</span> S. Dimple, B. Sourabh and P. Chandra, "A comprehensive survey on gait analysis: History," Artificial Intelligence in Medicine, vol. 129, p. 102341, 2022.</li>
                <li><span class="ieee-ref-list-number">[2]</span> Saboor, Abdul and Kask, Triin and Kuusik, Alar and Alam, Muhammad and Le Moullec, Yannick and Niazi, Imran and Zoha, Ahmed and Ahmad and Rizwan, "Latest Research Trends in Gait Analysis Using Wearable Sensors and Machine Learning: A Systematic Review," IEEE Access, vol. 8, 09 2020.</li>
                <li><span class="ieee-ref-list-number">[3]</span> Chen, Xin and Weng, Jian and Lu, Wei and Xu and Jiaming, "Multi-Gait Recognition Based on Attribute Discovery," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 7, pp. 1697-1710, 2018.</li>
                <li><span class="ieee-ref-list-number">[4]</span> Gaud, Neha and Rathore, Maya and Suman and Ugrasen, "Human Gait Analysis and Activity Recognition: A Review," 2023 IEEE Guwahati Subsection Conference (GCON), pp. 1-6, 2023.</li>
                <li><span class="ieee-ref-list-number">[5]</span> Yamamoto, Masataka and Shimatani, Koji and Ishige, uto and Takemura and Hiroshi, "Verification of gait analysis method fusing camera-based pose estimation and an IMU sensor in various gait conditions," Scientific Reports, vol. 12, 10 2022.</li>
                <li><span class="ieee-ref-list-number">[6]</span> Muro, Alvaro and Zapirain and Begoña and Mendez-Zorri, "Gait Analysis Methods: An Overview of Wearable and Non-Wearable Systems, Highlighting Clinical Applications," Sensors (Basel, Switzerland), vol. 14, pp. 3362-94, 02 2014.</li>
                <li><span class="ieee-ref-list-number">[7]</span> Avellar, Letícia and Leal Junior and Arnaldo and Diaz, "POF Smart Carpet: A Multiplexed Polymer Optical Fiber-Embedded Smart Carpet for Gait Analysis," Sensors, p. 3356, 07 2019.</li>
                <li><span class="ieee-ref-list-number">[8]</span> Chambers, Henry and Sutherland and David, "A Practical Guide to Gait Analysis," The Journal of the American Academy of Orthopaedic Surgeons, vol. 10, pp. 222-31, 05 2002.</li>
                <li><span class="ieee-ref-list-number">[9]</span> Pirker, Walter and Katzenschlager and Regina, "Gait disorders in adults and the elderly: A clinical guide," Wiener klinische Wochenschrift, vol. 129, 10 2016.</li>
                <li><span class="ieee-ref-list-number">[10]</span> Rueterbories, Jan and Spaich, Erika G. and Larsen, Birgit and Andersen and Ole, "Methods for gait detection and analysis in ambulatory systems," Medical engineering & physics, vol. 32, pp. 545-52, 04 2010.</li>
                <li><span class="ieee-ref-list-number">[11]</span> U. Keisuke, A. Penny R., N. M. Fiorentino and . A. Andrew E, "Hip rotation during standing and dynamic activities and the compensatory effect of femoral anteversion: An in-vivo analysis of asymptomatic young adults using three-dimensional computed tomography models and dual fluoroscopy," Gait & Posture, vol. 61, pp. 276-281, 2018.</li>
                <li><span class="ieee-ref-list-number">[12]</span> Warmerdam, Elke and Romijnders, Robbin and Welzel, Julius and Hansen, Clint and Schmidt, Gerhard and Maetzler and Walter, "Quantification of Arm Swing during Walking in Healthy Adults and Parkinson's Disease Patients: Wearable Sensor-Based Algorithm Development and Validation," Sensors, p. 105963, 2020.</li>
                <li><span class="ieee-ref-list-number">[13]</span> M. Pieter, S. M. Bruijn and Jacques, "The how and why of arm swing during human walking," Gait & Posture, vol. 38, no. 4, pp. 555-562, 2013.</li>
                <li><span class="ieee-ref-list-number">[14]</span> Sant'Anna, Anita and Wickström and Nicholas, "Symbolic Approach to Motion Analysis: Framework and Gait Analysis Case Studies," pp. 557-602, 01 2013.</li>
                <li><span class="ieee-ref-list-number">[15]</span> R. Aravinda, R. Marko, L. Yuguang, H. Songbo, F. Yihai, K. Kourosh, P. Marimuthu and N. Tuan, "Real-time monitoring of construction sites: Sensors, methods, and applications," Automation in Construction, vol. 136, p. 104099, 2022.</li>
                <li><span class="ieee-ref-list-number">[16]</span> "Accelerometer Sensor," Arduino, [Online]. Available: https://sensorkit.arduino.cc/sensorkit/module/lessons/lesson/09-the-accelerometer-sensor. [Accessed 17 09 2024].</li>
                <li><span class="ieee-ref-list-number">[17]</span> R. Lei, . J. Richard K. and H. David, "Whole body inverse dynamics over a complete gait cycle based only on measured kinematics," Journal of Biomechanics, vol. 41, no. 12, pp. 2750-2759, 2008.</li>
                <li><span class="ieee-ref-list-number">[18]</span> Çelik, Yunus and Stuart, Samuel and Woo, Wai Lok and Godfrey and Alan, "Wearable Inertial Gait Algorithms: Impact of Wear Location and Environment in Healthy and Parkinson's Populations," Sensors, 09 2021.</li>
                <li><span class="ieee-ref-list-number">[19]</span> Ekdahl, Mitchell and Loewen, Alex and Erdman, Ashley and Sahin, Sarp and Ulman and Sophia, "Inertial Measurement Unit Sensor-to-Segment Calibration Comparison for Sport-Specific Motion Analysis," Sensors, vol. 23, p. 7987, 09 2023.</li>
                <li><span class="ieee-ref-list-number">[20]</span> Z. Tobias, T. Bertram and B. Gabriele, "IMU-to-Segment Assignment and Orientation Alignment for the Lower Body Using Deep Learning," Sensors (Basel, Switzerland), vol. 18, 2018.</li>
                <li><span class="ieee-ref-list-number">[21]</span> Azdy, Rezania and Darnis and Febriyanti, "Use of Haversine Formula in Finding Distance Between Temporary Shelter and Waste End Processing Sites," Journal of Physics: Conference Series, vol. 1500, p. 012104, 04 2020.</li>
                <li><span class="ieee-ref-list-number">[22]</span> Chin, Robin and Hsiao-Wecksler, Elizabeth and Loth, Eric and Kogler, Geza and Manwaring, Scott and Tyson, Serena and Shorter, Kenneth and Gilmer and Joel, "A pneumatic power harvesting ankle-foot orthosis to prevent foot-drop," Journal of neuroengineering and rehabilitation, p. 19, 07 2009.</li>
                <li><span class="ieee-ref-list-number">[23]</span> W. Xingchen, K. Maria, R. Danijela, Durrant, S. Matthias and Axel, "Monitoring of gait performance using dynamic time warping on IMU-sensor data," 2016 IEEE International Symposium on Medical Measurements and Applications (MeMeA), pp. 1-6, 2016.</li>
                <li><span class="ieee-ref-list-number">[24]</span> Zhu, Jia-Xin and Wang, Weifeng and Huang, Shiping and Ding and Wei, "An Improved Calibration Technique for MEMS Accelerometer-Based Inclinometers," Sensors, vol. 20, p. 452, 01 2020.</li>
                <li><span class="ieee-ref-list-number">[25]</span> Galor, Noam, Zeilig, Gabriel and Plotnik and Meir, "A New Measure for Quantifying Four-Limb Coordination of Human Gait Based on Mobility Sensors," Sensors, 09 2024.</li>
                <li><span class="ieee-ref-list-number">[26]</span> O. Theresa, "Kinematics and kinetics of gait," MEDICOL, 2020.</li>
                <li><span class="ieee-ref-list-number">[27]</span> Chan, Carl W, Rubins and Andrew, "Foot Biomechanics During Walking and Running," vol. 69, no. 0025-6196, pp. 448-461, 0501 1994.</li>
                <li><span class="ieee-ref-list-number">[28]</span> R. Andersson, B.-G. Javier, A. Rafael, C. Mikael and C. José, "Smartphone IMU Sensors for Human Identification through Hip Joint Angle Analysis," Sensors (Basel, Switzerland), vol. 24, no. 15, p. 4769, 2024.</li>
            </ul>
        </section>
    </main>

    <!-- Footer -->
    <footer>
        <p>&copy; 2024 Osca Kholopha - MECN4006 Research Project</p>
        <p>University of the Witwatersrand</p>
        <p>Ethics Clearance: MIAEC 109/24W</p>
        <p>Email: <a href="mailto:oscakholopha@gmail.com">oscakholopha@gmail.com</a></p>
    </footer>

    <!-- Theme Toggle Button -->
    <button class="theme-toggle" onclick="toggleTheme()" id="themeIcon" title="Toggle Theme">☾</button>

    <!-- Back to Top Button -->
    <button class="back-to-top" id="backToTop" onclick="scrollToTop()">↑</button>

    <script src="script.js"></script>
    <script>
        // Theme Toggle Functionality
        function toggleTheme() {
            const body = document.body;
            const themeIcon = document.getElementById('themeIcon');
            
            body.classList.toggle('light-mode');
            
            if (body.classList.contains('light-mode')) {
                themeIcon.textContent = '☀';
                localStorage.setItem('theme', 'light');
            } else {
                themeIcon.textContent = '☾';
                localStorage.setItem('theme', 'dark');
            }
        }
        
        // Load saved theme on page load
        window.addEventListener('DOMContentLoaded', () => {
            const savedTheme = localStorage.getItem('theme');
            const themeIcon = document.getElementById('themeIcon');
            
            if (savedTheme === 'light') {
                document.body.classList.add('light-mode');
                themeIcon.textContent = '☀';
            }
        });
    </script>
</body>
</html>
